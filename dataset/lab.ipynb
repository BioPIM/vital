{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from __init__ import *\n",
    "\n",
    "__ORIG_WD__ = os.getcwd()\n",
    "os.chdir(f\"{__ORIG_WD__}/../data_collectors\")\n",
    "\n",
    "from covid19_genome import Covid19Genome\n",
    "\n",
    "os.chdir(__ORIG_WD__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Data frame\n",
      "Done building Data frame\n",
      "Building remote dicts\n",
      "Done building remote dicts\n",
      "Building local dicts\n",
      "Done building local dicts\n"
     ]
    }
   ],
   "source": [
    "dc = Covid19Genome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lineages = dc.getLocalLineages()\n",
    "\n",
    "mappings = []\n",
    "accessions = for lineage in lineages:\n",
    "    for accession in dc.getLocalAccessionsPaths(lineage):\n",
    "        mappings.append((accession, lineage))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 10)\n",
      "[0 1 2 2 1 2 2 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def compute_coverage(n, indexes, read_lengths):\n",
    "    # Create a range tensor [0, 1, 2, ... n-1]\n",
    "    range_tensor = tf.range(n, dtype=tf.int32)\n",
    "\n",
    "    # Expand dims for broadcasting\n",
    "    expanded_range = tf.expand_dims(range_tensor, 0)\n",
    "    expanded_indexes = tf.expand_dims(indexes, 1)\n",
    "    expanded_lengths = tf.expand_dims(read_lengths, 1)\n",
    "\n",
    "    # Create a binary mask for each read\n",
    "    # Each row in the mask represents where the read starts and its length\n",
    "    print((expanded_range >= expanded_indexes).shape)\n",
    "    mask = tf.logical_and(expanded_range >= expanded_indexes,\n",
    "                          expanded_range < expanded_indexes + expanded_lengths)\n",
    "\n",
    "    # Convert the boolean mask to integers and sum across rows\n",
    "    coverage = tf.reduce_sum(tf.cast(mask, tf.int32), axis=0)\n",
    "    \n",
    "    return coverage\n",
    "\n",
    "# Example\n",
    "n = 10\n",
    "indexes = tf.constant([1, 2, 5], dtype=tf.int32)\n",
    "read_lengths = tf.constant([3, 20, 2], dtype=tf.int32)\n",
    "\n",
    "coverage_per_base = compute_coverage(n, indexes, read_lengths)\n",
    "print(coverage_per_base.numpy())  # Expected: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Cannot convert the argument `type_value`: [0] to a TensorFlow DType.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/covit/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:94\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 94\u001b[0m   dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39;49mas_datatype_enum\n\u001b[1;32m     95\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'as_datatype_enum'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tf\u001b[39m.\u001b[39mtensor_scatter_nd_add(\n\u001b[0;32m----> 2\u001b[0m     tf\u001b[39m.\u001b[39mzeros([\u001b[39m3\u001b[39m], tf\u001b[39m.\u001b[39;49mconstant([\u001b[39m0\u001b[39;49m], [\u001b[39m0\u001b[39;49m]), tf\u001b[39m.\u001b[39mconstant([\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m]))\n\u001b[1;32m      3\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/covit/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:263\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    168\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \n\u001b[1;32m    170\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 263\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    264\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/covit/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:275\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    274\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 275\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    277\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    278\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    279\u001b[0m )\n\u001b[1;32m    280\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/miniconda3/envs/covit/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:285\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    284\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 285\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    286\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    287\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/miniconda3/envs/covit/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py:96\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     94\u001b[0m     dtype \u001b[39m=\u001b[39m dtype\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m     95\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39;49mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39mEagerTensor(value, ctx\u001b[39m.\u001b[39mdevice_name, dtype)\n",
      "File \u001b[0;32m~/miniconda3/envs/covit/lib/python3.9/site-packages/tensorflow/python/framework/dtypes.py:846\u001b[0m, in \u001b[0;36mas_dtype\u001b[0;34m(type_value)\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(type_value, _dtypes\u001b[39m.\u001b[39mDType):\n\u001b[1;32m    844\u001b[0m   \u001b[39mreturn\u001b[39;00m _INTERN_TABLE[type_value\u001b[39m.\u001b[39mas_datatype_enum]\n\u001b[0;32m--> 846\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot convert the argument `type_value`: \u001b[39m\u001b[39m{\u001b[39;00mtype_value\u001b[39m!r}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    847\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mto a TensorFlow DType.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot convert the argument `type_value`: [0] to a TensorFlow DType."
     ]
    }
   ],
   "source": [
    "tf.tensor_scatter_nd_add(\n",
    "    tf.zeros([3], tf.constant([0], [0]), tf.constant([1,1]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 14:56:23.750716: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-08-29 14:56:23.819231: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-29 14:56:25.214459: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-08-29 14:56:26.678762: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 -1 -1 -1 -1 -2 -2 -2 -2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-29 14:56:26.720511: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-29 14:56:26.720751: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-29 14:56:26.723778: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-29 14:56:26.724745: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-29 14:56:26.725031: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-29 14:56:27.804371: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-29 14:56:27.804646: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-29 14:56:27.804725: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-08-29 14:56:27.804817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 478 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def propagate_values(vector):\n",
    "    # Find where the vector is not zero\n",
    "    non_zeros = tf.cast(tf.not_equal(vector, 0), dtype=tf.int32)\n",
    "\n",
    "    # Get the cumulative sum of non-zero locations\n",
    "    cum_sum = tf.cumsum(non_zeros)\n",
    "\n",
    "    # Create a mask to gather elements\n",
    "    mask = cum_sum * non_zeros\n",
    "\n",
    "    # Use tf.gather to replace zeros with latest non-zero value\n",
    "    propagated_values = tf.gather(tf.boolean_mask(vector, mask), cum_sum - 1)\n",
    "\n",
    "    return propagated_values\n",
    "\n",
    "# Example\n",
    "vec = tf.constant([0, 0, 0, -1, 0, 0, 0, -2, 0, 0, 0], dtype=tf.int32)\n",
    "result = propagate_values(vec)\n",
    "print(result.numpy())  # Expected: [0,0,0,3,3,3,3,3,8,8,8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'diff'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant([\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m,\u001b[39m4\u001b[39m,\u001b[39m5\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m tf\u001b[39m.\u001b[39;49mdiff(a)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'diff'"
     ]
    }
   ],
   "source": [
    "a = tf.constant([1,2,3,4,5])\n",
    "tf.diff(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_partition(balls, bins):\n",
    "    \"\"\"\n",
    "    1 represents a ball\n",
    "    0 represents a partition\n",
    "    \"\"\"\n",
    "    # randomize the ones indexes\n",
    "    balls_indexes = tf.random.shuffle(tf.range(balls+bins-1))[:balls]\n",
    "    balls_and_partitions = tf.concat([\n",
    "        tf.scatter_nd(\n",
    "            indices=tf.expand_dims(balls_indexes, 1),\n",
    "            updates=tf.ones(balls, dtype=tf.dtypes.int32),\n",
    "            shape=[bins+balls-1]\n",
    "        ), \n",
    "        [0]\n",
    "    ], axis=-1)\n",
    "    \n",
    "    # cumsum of balls and partitions\n",
    "    cumsum = tf.cumsum(balls_and_partitions)\n",
    "\n",
    "    summed_balls_per_partition = tf.boolean_mask(cumsum, balls_and_partitions == 0)\n",
    "\n",
    "    prev_balls_per_partition = tf.concat([[0], summed_balls_per_partition[:-1]], axis = -1)\n",
    "\n",
    "    return summed_balls_per_partition - prev_balls_per_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_coverage_per_base(genome_length, read_length, coverage):\n",
    "    num_reads = tf.cast(tf.math.ceil(coverage * genome_length / read_length), tf.int32)\n",
    "    read_starts_per_base = tf.concat(\n",
    "        [\n",
    "            random_partition(\n",
    "                balls = num_reads,\n",
    "                bins = genome_length - read_length + 1,\n",
    "            ),\n",
    "            tf.zeros(read_length, dtype=tf.int32)\n",
    "        ],\n",
    "        axis=-1\n",
    "    )\n",
    "    tf.print(read_starts_per_base)\n",
    "    read_ends_per_base = -1*tf.roll(read_starts_per_base, read_length, axis=0)\n",
    "    tf.print(read_ends_per_base)\n",
    "    coverage_per_base = tf.cumsum(read_starts_per_base + read_ends_per_base)\n",
    "    return coverage_per_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 1 3 3 0]\n",
      "[0 -6 -1 -3 -3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=int32, numpy=array([6, 1, 3, 3, 0], dtype=int32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_compute_coverage_per_base(5, 2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
