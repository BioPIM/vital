{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training covid models\n",
    "### This notebook is an example usage of how to use the model alongside the covid-data-collector in order to train, evaluate and test the model\n",
    "#### In this notebook you will find example usages on how to use the core functionalities of the model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import third party modules, and also the data_collector: covid19_genome and the model module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 16:49:44.663348: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-19 16:49:44.687758: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-19 16:49:45.108611: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # Uncomment to disable GPU\n",
    "import glob\n",
    "\n",
    "from model import Model, DatasetName, load_model, remove_model\n",
    "\n",
    "__ORIG_WD__ = os.getcwd()\n",
    "\n",
    "os.chdir(f\"{__ORIG_WD__}/../data_collectors/\")\n",
    "from covid19_genome import Covid19Genome\n",
    "\n",
    "os.chdir(__ORIG_WD__)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a model, or try to load it, if it was already have been created.\n",
    "\n",
    "In order to use the model, the first thing you have to do is provide it with a dataset (with the help of the data_collector). In the following cell you are provided with an example that create the dataset.\n",
    "\n",
    "You should note that when you are creating the dataset, you are passing the dataset type. You can obtain the available dataset types in the system by calling the model class function ```get_ds_types()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 16:49:45.504387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 16:49:45.519640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 16:49:45.519753: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 16:49:45.520683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 16:49:45.520758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 16:49:45.520805: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 16:49:45.834472: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 16:49:45.834587: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 16:49:45.834638: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 16:49:45.834687: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22325 MB memory:  -> device: 0, name: NVIDIA RTX A5000, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "model_name = \"cov19-1024e\"\n",
    "\n",
    "try:\n",
    "    print(\"loading model\")\n",
    "    model = load_model(model_name)\n",
    "except Exception:\n",
    "    print(\"creating model\")\n",
    "    covid19_genome = Covid19Genome()\n",
    "    lineages = covid19_genome.getLocalLineages(1024)\n",
    "    lineages.sort()\n",
    "    dataset = []\n",
    "    def get_dataset():\n",
    "        for lineage in lineages:\n",
    "            dataset.append((lineage, covid19_genome.getLocalAccessionsPath(lineage)))\n",
    "        return dataset\n",
    "\n",
    "    portions = {\n",
    "        DatasetName.trainset.name: 0.8,\n",
    "        DatasetName.validset.name: 0.1,\n",
    "        DatasetName.testset.name: 0.1\n",
    "    }\n",
    "\n",
    "    dataset = get_dataset()\n",
    "    model = Model(model_name)\n",
    "    model.create_datasets(model.get_ds_types()[0], dataset, portions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have created the model, and created its datasets. You can check which neural network structures is available. You can do that by calling the model class function ```get_ml_model_structure()```.\n",
    "\n",
    "After you see all the ml_model structures available in the system, you can check which hyper parameters are needed to define each and every ml_model structure. This is done by calling the model class function ```get_ml_model_structure_hps()```. The ```get_ml_model_structure_hps()``` will return which hps are required, and what it their type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VitStructure', 'ConvStructure']\n",
      "{'convclass': 'required', 'convnet': 'required', 'labels': 'required', 'seq_len': 'required', 'd_model': 'required'}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_ml_model_structures())\n",
    "print(model.get_ml_model_structure_hps(model.get_ml_model_structures()[-1]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see which properties help define the current type of dataset by calling to the model class function ```get_ds_props()``` This function could be called only after the dataset have been succesfully created. This function will return the properties of the dataset as well as their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': 4, 'substitution_rate': 0.005, 'insertion_rate': 0.001, 'deletion_rate': 0.001, 'read_length': 128, 'frag_len': 128, 'num_frags': 256}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_ds_props())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A use case of the system with the VitStructure model and the minhash genome datasets (a.k.a. mh_genome_ds).\n",
    "\n",
    "In the mh_genome_ds the coverage is a dataset property that sets the genome coverage rate.\n",
    "\n",
    "In the VitStructure, the model_depth is the number of transformer encoders.\n",
    "\n",
    "In this example use-case these two parameters will help us define a neural network that will be trained on the dataset (with the current coverage rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = 4\n",
    "ml_model_depth = 1\n",
    "sequencer_instrument = \"illumina\"\n",
    "batch_size = 1024\n",
    "mini_batch_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequencer_instrument_to_error_profile_map = {\n",
    "    \"illumina\": {\n",
    "        \"substitution_rate\": 0.005,\n",
    "        \"insertion_rate\": 0.001,\n",
    "        \"deletion_rate\": 0.001\n",
    "    },\n",
    "    \"ont\": {\n",
    "        \"substitution_rate\": 0.01,\n",
    "        \"insertion_rate\": 0.04,\n",
    "        \"deletion_rate\": 0.04\n",
    "    },\n",
    "    \"pacbio\": {\n",
    "        \"substitution_rate\": 0.005,\n",
    "        \"insertion_rate\": 0.025,\n",
    "        \"deletion_rate\": 0.025\n",
    "    },\n",
    "    \"roche\": {\n",
    "        \"substitution_rate\": 0.002,\n",
    "        \"insertion_rate\": 0.01,\n",
    "        \"deletion_rate\": 0.01\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_model_name(ml_model_depth, coverage, sequencer_instrument):\n",
    "    if not sequencer_instrument in sequencer_instrument_to_error_profile_map:\n",
    "        raise Exception(f\"Invalid sequencer instrument: {sequencer_instrument}\")\n",
    "    return f\"vit.{ml_model_depth}.{coverage}x.{sequencer_instrument}\"\n",
    "\n",
    "ml_model_name = get_model_name(ml_model_depth, coverage, sequencer_instrument)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a new neural network\n",
    "\n",
    "In this cell we will create an ml_model with the required hps (and also optional) as outputted earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists\n"
     ]
    }
   ],
   "source": [
    "newly_added = True\n",
    "try:\n",
    "    model.add_ml_model(ml_model_name, hps={\n",
    "        \"structure\": model.get_ml_model_structures()[0],\n",
    "        \"d_model\": model.get_ds_props()[\"frag_len\"],\n",
    "        \"seq_len\": model.get_ds_props()[\"num_frags\"],\n",
    "        \"d_val\": 128,\n",
    "        \"d_key\": 128,\n",
    "        \"heads\": 8,\n",
    "        \"d_ff\": 1024+256,\n",
    "        \"labels\":  len(model.get_labels()),\n",
    "        \"activation\": \"relu\",\n",
    "        \"optimizer\": {\n",
    "            \"name\": \"AdamW\",\n",
    "            \"params\": {\n",
    "                \"learning_rate\": 0.001,\n",
    "            },\n",
    "        },\n",
    "        \"encoder_repeats\": ml_model_depth,\n",
    "        \"regularizer\": {\n",
    "            \"name\": \"l2\",\n",
    "            \"params\": {\n",
    "                \"l2\": 0.0001\n",
    "            }\n",
    "        },\n",
    "        \"dropout\": 0.2,\n",
    "    })\n",
    "except:\n",
    "    newly_added = False\n",
    "    print(\"Model already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml_model_class = \"efficientnet\"\n",
    "# ml_model_name = \"efficient_net_b0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['VitStructure', 'ConvStructure']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model.get_ml_model_structures()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'Exception'>\n",
      "ML model efficient_net_b0 already exists.\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# try:\n",
    "#     model.add_ml_model(ml_model_name, hps={\n",
    "#         \"structure\": model.get_ml_model_structures()[-1],\n",
    "#         \"convclass\": ml_model_class,\n",
    "#         \"convnet\": ml_model_name,\n",
    "#         \"seq_len\": model.get_ds_props()[\"num_frags\"],\n",
    "#         \"d_model\": model.get_ds_props()[\"frag_len\"],\n",
    "#         \"labels\":  len(model.get_labels()),\n",
    "#         \"batch_size\": batch_size,\n",
    "#         \"mini_batch_size\": mini_batch_size,\n",
    "#     })\n",
    "# except:\n",
    "#     # print exception info\n",
    "#     print(sys.exc_info()[0])\n",
    "#     print(sys.exc_info()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['efficient_net_b0', 'vit.1.4x.illumina']\n"
     ]
    }
   ],
   "source": [
    "models = model.list_ml_models()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if newly_added:\n",
    "#     assert False, \"Please consider doing transfer learning\"\n",
    "# # model.transfer(get_model_name(ml_model_depth, coverage * 2, sequencer_instrument), ml_model_name, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.change_ml_hps(ml_model_name, {\n",
    "#     \"regularizer\": {\n",
    "#         \"name\": \"l2\",\n",
    "#         \"params\": {\n",
    "#             \"l2\": 0.00005,\n",
    "#         },\n",
    "#     },\n",
    "#     \"optimizer\": {\n",
    "#         \"name\": \"AdamW\",\n",
    "#         \"params\": {\n",
    "#             \"learning_rate\": 0.0002,\n",
    "#         },\n",
    "#     },\n",
    "# })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating the dataset coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.update_ds_props({\n",
    "    \"coverage\": coverage,\n",
    "    } | sequencer_instrument_to_error_profile_map[sequencer_instrument])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting dataset batch size and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mini_batch_size = batch_size\n",
    "# while(True):\n",
    "#     try:\n",
    "#         model.set_ds_batch_size(mini_batch_size)\n",
    "#         model.train(ml_model_name, epochs=30)\n",
    "#     except:\n",
    "#         mini_batch_size = int(mini_batch_size // 2)\n",
    "#         model.change_ml_hps(ml_model_name, {\n",
    "#             \"batch_size\": mini_batch_size,\n",
    "#         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/applications/efficientnet.py:321: UserWarning: This model usually expects 1 or 3 input channels. However, it was passed an input_shape with 4 input channels.\n",
      "  input_shape = imagenet_utils.obtain_input_shape(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compiled the model with the following metrics: ['categorical_accuracy', 'AUC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 16:49:49.394413: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8600\n",
      "2024-01-19 16:49:49.785955: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 16:49:57.989468: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inefficientnetb0/block2b_drop/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/601 [..............................] - ETA: 5:12 - categorical_accuracy: 0.3021 - loss: 2.3557 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 16:50:06.268676: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x9d56f510 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-01-19 16:50:06.268786: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA RTX A5000, Compute Capability 8.6\n",
      "2024-01-19 16:50:06.280088: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-01-19 16:50:06.462639: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "601/601 [==============================] - 376s 604ms/step - categorical_accuracy: 0.3731 - loss: 2.1486 - val_categorical_accuracy: 0.3779 - val_loss: 2.1573\n",
      "Epoch 2/30\n",
      "601/601 [==============================] - 352s 586ms/step - categorical_accuracy: 0.4482 - loss: 1.8454 - val_categorical_accuracy: 0.4518 - val_loss: 1.8496\n",
      "Epoch 3/30\n",
      "601/601 [==============================] - 359s 598ms/step - categorical_accuracy: 0.5057 - loss: 1.6231 - val_categorical_accuracy: 0.5009 - val_loss: 1.6848\n",
      "Epoch 4/30\n",
      " 77/601 [==>...........................] - ETA: 4:22 - categorical_accuracy: 0.5321 - loss: 1.5290"
     ]
    }
   ],
   "source": [
    "model.set_ds_batch_size(mini_batch_size)\n",
    "model.train(ml_model_name, epochs=30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
