{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training covid models\n",
    "### This notebook is an example usage of how to use the model alongside the covid-data-collector in order to train, evaluate and test the model\n",
    "#### In this notebook you will find example usages on how to use the core functionalities of the model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import third party modules, and also the data_collector: covid19_genome and the model module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\" # Uncomment to disable GPU\n",
    "import glob\n",
    "\n",
    "from model import Model, DatasetName, load_model, remove_model\n",
    "\n",
    "__ORIG_WD__ = os.getcwd()\n",
    "\n",
    "os.chdir(f\"{__ORIG_WD__}/../data_collectors/\")\n",
    "from covid19_genome import Covid19Genome\n",
    "\n",
    "os.chdir(__ORIG_WD__)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a model, or try to load it, if it was already have been created.\n",
    "\n",
    "In order to use the model, the first thing you have to do is provide it with a dataset (with the help of the data_collector). In the following cell you are provided with an example that create the dataset.\n",
    "\n",
    "You should note that when you are creating the dataset, you are passing the dataset type. You can obtain the available dataset types in the system by calling the model class function ```get_ds_types()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"covid19-1024examples\"\n",
    "\n",
    "try:\n",
    "    model = load_model(model_name)\n",
    "except Exception:\n",
    "    covid19_genome = Covid19Genome()\n",
    "    lineages = covid19_genome.getLocalLineages(1024)\n",
    "    lineages.sort()\n",
    "    dataset = []\n",
    "    def get_dataset():\n",
    "        for lineage in lineages:\n",
    "            dataset.append((lineage, covid19_genome.getLocalAccessionsPath(lineage)))\n",
    "        return dataset\n",
    "\n",
    "    portions = {\n",
    "        DatasetName.trainset.name: 0.8,\n",
    "        DatasetName.validset.name: 0.1,\n",
    "        DatasetName.testset.name: 0.1\n",
    "    }\n",
    "\n",
    "    dataset = get_dataset()\n",
    "    model = Model(model_name)\n",
    "    model.create_datasets(model.get_ds_types()[0], dataset, portions)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After you have created the model, and created its datasets. You can check which neural network structures is available. You can do that by calling the model class function ```get_ml_model_structure()```.\n",
    "\n",
    "After you see all the ml_model structures available in the system, you can check which hyper parameters are needed to define each and every ml_model structure. This is done by calling the model class function ```get_ml_model_structure_hps()```. The ```get_ml_model_structure_hps()``` will return which hps are required, and what it their type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VitStructure', 'IreneStructure', 'SandyStructure']\n",
      "{'d_model': 'required', 'd_val': 'required', 'd_key': 'required', 'd_ff': 'required', 'heads': 'required', 'dropout_rate': 'optional', 'regularizer': 'optional', 'initializer': 'optional', 'activation': 'optional', 'encoder_repeats': 'required', 'labels': 'required'}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_ml_model_structures())\n",
    "print(model.get_ml_model_structure_hps(model.get_ml_model_structures()[0]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also see which properties help define the current type of dataset by calling to the model class function ```get_ds_props()``` This function could be called only after the dataset have been succesfully created. This function will return the properties of the dataset as well as their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'coverage': 2, 'substitution_rate': 0.005, 'insertion_rate': 0.025, 'deletion_rate': 0.025, 'read_length': 128, 'frag_len': 128, 'num_frags': 256}\n"
     ]
    }
   ],
   "source": [
    "print(model.get_ds_props())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A use case of the system with the VitStructure model and the minhash genome datasets (a.k.a. mh_genome_ds).\n",
    "\n",
    "In the mh_genome_ds the coverage is a dataset property that sets the genome coverage rate.\n",
    "\n",
    "In the VitStructure, the model_depth is the number of transformer encoders.\n",
    "\n",
    "In this example use-case these two parameters will help us define a neural network that will be trained on the dataset (with the current coverage rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = 2\n",
    "ml_model_depth = 6\n",
    "sequencer_instrument = \"pacbio\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit.6.2x.pacbio\n"
     ]
    }
   ],
   "source": [
    "sequencer_instrument_to_error_profile_map = {\n",
    "    \"illumina\": {\n",
    "        \"substitution_rate\": 0.005,\n",
    "        \"insertion_rate\": 0.001,\n",
    "        \"deletion_rate\": 0.001\n",
    "    },\n",
    "    \"ont\": {\n",
    "        \"substitution_rate\": 0.01,\n",
    "        \"insertion_rate\": 0.04,\n",
    "        \"deletion_rate\": 0.04\n",
    "    },\n",
    "    \"pacbio\": {\n",
    "        \"substitution_rate\": 0.005,\n",
    "        \"insertion_rate\": 0.025,\n",
    "        \"deletion_rate\": 0.025\n",
    "    },\n",
    "    \"roche\": {\n",
    "        \"substitution_rate\": 0.002,\n",
    "        \"insertion_rate\": 0.01,\n",
    "        \"deletion_rate\": 0.01\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_model_name(ml_model_depth, coverage, sequencer_instrument):\n",
    "    if not sequencer_instrument in sequencer_instrument_to_error_profile_map:\n",
    "        raise Exception(f\"Invalid sequencer instrument: {sequencer_instrument}\")\n",
    "    return f\"vit.{ml_model_depth}.{coverage}x.{sequencer_instrument}\"\n",
    "\n",
    "ml_model_name = get_model_name(ml_model_depth, coverage, sequencer_instrument)\n",
    "print(ml_model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a new neural network\n",
    "\n",
    "In this cell we will create an ml_model with the required hps (and also optional) as outputted earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model already exists\n"
     ]
    }
   ],
   "source": [
    "newly_added = True\n",
    "# model.remove_ml_model(ml_model_name)\n",
    "try:\n",
    "    model.add_ml_model(ml_model_name, hps={\n",
    "        \"structure\": model.get_ml_model_structures()[0],\n",
    "        \"d_model\": model.get_ds_props()[\"frag_len\"],\n",
    "        \"d_val\": 128,\n",
    "        \"d_key\": 128,\n",
    "        \"heads\": 8,\n",
    "        \"d_ff\": 1024+256,\n",
    "        \"labels\":  len(model.get_labels()),\n",
    "        \"activation\": \"relu\",\n",
    "        \"optimizer\": {\n",
    "            \"name\": \"AdamW\",\n",
    "            \"params\": {\n",
    "                \"learning_rate\": 0.001,\n",
    "            },\n",
    "        },\n",
    "        \"encoder_repeats\": ml_model_depth,\n",
    "        \"regularizer\": {\n",
    "            \"name\": \"l2\",\n",
    "            \"params\": {\n",
    "                \"l2\": 0.0001\n",
    "            }\n",
    "        },\n",
    "        \"dropout_rate\": 0.1,\n",
    "    })\n",
    "except:\n",
    "    newly_added = False\n",
    "    print(\"Model already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vit.2.4x.pacbio', 'vit.6.2x.pacbio', 'vit.2.2x.illumina', 'vit.2.1x.illumina', 'meow', 'vit.1.2x.pacbio', 'vit.1.4x.roche', 'vit.2.4x.roche', 'sandy.1.2x.pacbio', 'vit.2.2x.pacbio', 'vit.2.2x.roche', 'irene.1.2x.pacbio', 'vit.2.1x.roche', 'vit.3.2x.pacbio', 'vit.2.1x.pacbio', 'vit.2.4x.illumina', 'vit.3.1x.illumina', 'vit.1.4x.illumina']\n"
     ]
    }
   ],
   "source": [
    "models = model.list_ml_models()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if newly_added:\n",
    "#    assert False, \"Please consider doing transfer learning\"\n",
    "# model.transfer(get_model_name(ml_model_depth-3, coverage, sequencer_instrument), ml_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.change_ml_hps(ml_model_name, {\n",
    "#     \"regularizer\": {        \n",
    "#         \"name\": \"l2\",\n",
    "#         \"params\": {\n",
    "#             \"l2\": model.get_ml_hps(ml_model_name)[\"regularizer\"][\"params\"][\"l2\"] * 0.5,\n",
    "#         },\n",
    "#    },\n",
    "#    \"optimizer\": {\n",
    "#        \"name\": \"AdamW\",\n",
    "#        \"params\": {\n",
    "#             \"learning_rate\": model.get_ml_hps(ml_model_name)[\"optimizer\"][\"params\"][\"learning_rate\"] * 0.5,\n",
    "#         },\n",
    "#     },\n",
    "    # \"dropout_rate\": model.get_ml_hps(ml_model_name)[\"dropout_rate\"] * 0.5,\n",
    "})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Updating the dataset coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.update_ds_props({\n",
    "    \"coverage\": coverage,\n",
    "    } | sequencer_instrument_to_error_profile_map[sequencer_instrument])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vit_structure_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_39 (Dense)            multiple                  5         \n",
      "                                                                 \n",
      " encoder_18 (Encoder)        multiple                  857088    \n",
      "                                                                 \n",
      " encoder_19 (Encoder)        multiple                  857088    \n",
      "                                                                 \n",
      " encoder_20 (Encoder)        multiple                  857088    \n",
      "                                                                 \n",
      " encoder_21 (Encoder)        multiple                  857088    \n",
      "                                                                 \n",
      " encoder_22 (Encoder)        multiple                  857088    \n",
      "                                                                 \n",
      " encoder_23 (Encoder)        multiple                  857088    \n",
      "                                                                 \n",
      " softmax_dense (Dense)       multiple                  21543     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5164076 (19.70 MB)\n",
      "Trainable params: 2592807 (9.89 MB)\n",
      "Non-trainable params: 2571269 (9.81 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.get_model_summary(ml_model_name)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting dataset batch size and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-18 09:15:10.074867: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.077048: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.127052: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.131793: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.176856: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.179979: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.221080: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.227455: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.244140: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.244825: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.256125: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.256799: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.267719: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.268458: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.279471: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.280511: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.292888: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.293734: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.305535: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.306347: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.319805: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.320622: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.332205: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.333281: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.344499: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.345159: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.356536: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.357226: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.369130: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.369999: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.381437: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.382390: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.393849: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.394571: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.406406: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.407098: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.418157: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.418912: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.430075: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.431007: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.442007: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.442605: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.453582: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.454298: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.465004: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.466007: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.477422: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.478336: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.491872: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.492906: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.507032: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.507845: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.519825: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.520708: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.532089: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.533149: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.544221: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.544892: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.556623: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.557392: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.569134: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.569925: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.581538: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.582546: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.593935: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.594664: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.606698: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.607428: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.618530: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.619310: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.630201: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.631291: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.642701: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.643429: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.654819: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.655485: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.665975: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.666885: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.677556: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.678095: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.688687: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.689331: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.700088: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.701068: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.712118: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.712922: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.724528: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.725140: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.735768: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.736468: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.747058: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.747920: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.758686: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.759234: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.769774: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.770443: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.780903: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.781726: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.792430: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.793004: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.803912: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.804613: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.814975: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.815889: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.826337: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.826875: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.837705: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.838380: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.848445: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.849313: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.859871: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.860423: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.871146: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.871949: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.883366: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.884479: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.895436: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.896511: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.909007: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.909823: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.922523: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.923326: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.936070: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.936965: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.948735: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.949690: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.961167: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.961984: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.974060: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.974821: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.986491: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.987320: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:10.999312: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.000477: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.011929: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.012894: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.024904: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.025681: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.037621: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.038420: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.050167: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.051458: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.063966: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.065171: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.077926: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.078742: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.090514: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.091320: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.103360: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.104230: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.116134: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.117391: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.129474: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.130752: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.143066: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.143846: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.156117: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.156912: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.168670: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.169537: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.181260: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.182380: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.193894: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.194698: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.206794: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.207577: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.219497: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.220317: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.231734: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.232793: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.244643: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.245447: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.257656: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.258506: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.270591: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.271433: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.283152: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.284362: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.295449: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.296673: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.308720: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.309413: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.320871: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.321630: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.332983: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.334216: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.345708: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.346787: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.358079: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.358694: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.369685: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.370459: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.381503: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.382579: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.393763: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.394516: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.405863: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.406598: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.417986: W tensorflow/compiler/xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc:273] libdevice is required by this HLO module but was not found at ./libdevice.10.bc\n",
      "2023-09-18 09:15:11.418830: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at xla_ops.cc:503 : INTERNAL: libdevice not found at ./libdevice.10.bc\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Graph execution error:\n\nDetected at node 'AdamW/StatefulPartitionedCall_99' defined at (most recent call last):\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2502418/2406946855.py\", line 2, in <module>\n      model.train(ml_model_name, epochs=1000)\n    File \"/home/zuherj/codehub/active/vital/models/model.py\", line 324, in train\n      self.ml_models[ml_model_name].train(\n    File \"/home/zuherj/codehub/active/vital/models/ml_models/ml_model.py\", line 195, in train\n      return self.net.fit(\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'AdamW/StatefulPartitionedCall_99'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node AdamW/StatefulPartitionedCall_99}}]] [Op:__inference_train_function_42263]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model\u001b[39m.\u001b[39mset_ds_batch_size(\u001b[39m120\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m model\u001b[39m.\u001b[39;49mtrain(ml_model_name, epochs\u001b[39m=\u001b[39;49m\u001b[39m1000\u001b[39;49m)\n",
      "File \u001b[0;32m~/codehub/active/vital/models/model.py:324\u001b[0m, in \u001b[0;36mModel.train\u001b[0;34m(self, ml_model_name, epochs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ml_model_name \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mml_models:\n\u001b[1;32m    321\u001b[0m     \u001b[39m# load the model\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_load_ml_model(ml_model_name)\n\u001b[0;32m--> 324\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mml_models[ml_model_name]\u001b[39m.\u001b[39;49mtrain(\n\u001b[1;32m    325\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    326\u001b[0m     trainset\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[DatasetName\u001b[39m.\u001b[39;49mtrainset\u001b[39m.\u001b[39;49mname],\n\u001b[1;32m    327\u001b[0m     validset\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdatasets[DatasetName\u001b[39m.\u001b[39;49mvalidset\u001b[39m.\u001b[39;49mname],\n\u001b[1;32m    328\u001b[0m )\n",
      "File \u001b[0;32m~/codehub/active/vital/models/ml_models/ml_model.py:195\u001b[0m, in \u001b[0;36mMLModel.train\u001b[0;34m(self, epochs, trainset, shuffle_buffer_size, validset)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnet\u001b[39m.\u001b[39mfit(\n\u001b[1;32m    188\u001b[0m         trainset\u001b[39m.\u001b[39mget_tf_dataset(shuffle_buffer_size\u001b[39m=\u001b[39mshuffle_buffer_size),\n\u001b[1;32m    189\u001b[0m         batch_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhps\u001b[39m.\u001b[39mget(HPs\u001b[39m.\u001b[39mattributes\u001b[39m.\u001b[39mbatch_size\u001b[39m.\u001b[39mname),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    192\u001b[0m         callbacks\u001b[39m=\u001b[39m[MLModelSaveCallback(\u001b[39mself\u001b[39m)]\n\u001b[1;32m    193\u001b[0m     )\n\u001b[1;32m    194\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 195\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnet\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    196\u001b[0m         trainset\u001b[39m.\u001b[39;49mget_tf_dataset(shuffle_buffer_size\u001b[39m=\u001b[39;49mshuffle_buffer_size),\n\u001b[1;32m    197\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    198\u001b[0m         steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mint\u001b[39;49m(trainset\u001b[39m.\u001b[39;49mget_size() \u001b[39m/\u001b[39;49m trainset\u001b[39m.\u001b[39;49mget_batch_size()),\n\u001b[1;32m    199\u001b[0m         validation_data\u001b[39m=\u001b[39;49mvalidset\u001b[39m.\u001b[39;49mget_tf_dataset(repeats\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m),\n\u001b[1;32m    200\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[MLModelSaveCallback(\u001b[39mself\u001b[39;49m)]\n\u001b[1;32m    201\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/vital/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInternalError\u001b[0m: Graph execution error:\n\nDetected at node 'AdamW/StatefulPartitionedCall_99' defined at (most recent call last):\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/traitlets/config/application.py\", line 1041, in launch_instance\n      app.start()\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/kernelapp.py\", line 724, in start\n      self.io_loop.start()\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 512, in dispatch_queue\n      await self.process_one()\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 501, in process_one\n      await dispatch(*args)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 408, in dispatch_shell\n      await result\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/kernelbase.py\", line 731, in execute_request\n      reply_content = await reply_content\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 417, in do_execute\n      res = shell.run_cell(\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/ipykernel/zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2945, in run_cell\n      result = self._run_cell(\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3000, in _run_cell\n      return runner(coro)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3203, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3382, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"/home/zuherj/.local/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 3442, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"/tmp/ipykernel_2502418/2406946855.py\", line 2, in <module>\n      model.train(ml_model_name, epochs=1000)\n    File \"/home/zuherj/codehub/active/vital/models/model.py\", line 324, in train\n      self.ml_models[ml_model_name].train(\n    File \"/home/zuherj/codehub/active/vital/models/ml_models/ml_model.py\", line 195, in train\n      return self.net.fit(\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1742, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1338, in train_function\n      return step_function(self, iterator)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1322, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1303, in run_step\n      outputs = model.train_step(data)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/engine/training.py\", line 1084, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 544, in minimize\n      self.apply_gradients(grads_and_vars)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1230, in apply_gradients\n      return super().apply_gradients(grads_and_vars, name=name)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 652, in apply_gradients\n      iteration = self._internal_apply_gradients(grads_and_vars)\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1260, in _internal_apply_gradients\n      return tf.__internal__.distribute.interim.maybe_merge_call(\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1352, in _distributed_apply_gradients_fn\n      distribution.extended.update(\n    File \"/home/zuherj/miniconda3/envs/vital/lib/python3.9/site-packages/keras/src/optimizers/optimizer.py\", line 1347, in apply_grad_to_update_var\n      return self._update_step_xla(grad, var, id(self._var_key(var)))\nNode: 'AdamW/StatefulPartitionedCall_99'\nlibdevice not found at ./libdevice.10.bc\n\t [[{{node AdamW/StatefulPartitionedCall_99}}]] [Op:__inference_train_function_42263]"
     ]
    }
   ],
   "source": [
    "model.set_ds_batch_size(120)\n",
    "model.train(ml_model_name, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
